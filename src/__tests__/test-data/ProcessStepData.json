{
  "id": "1eef14a0-ff0c-4f43-9416-e9c871326c82",
  "name": [
    {
      "languageCode": "en",
      "languageText": "Test Process step"
    }
  ],
  "description": [
    {
      "languageCode": "en",
      "languageText": "A process step specifically designed for testing"
    }
  ],
  "createdDate": "2019-09-23T12:50:15.456Z",
  "createdBy": "Test user",
  "version": "1.0.1",
  "versionValidFrom": "2019-09-24T08:53:24.134Z",
  "lastUpdatedDate": "2019-09-24T08:53:24.134Z",
  "lastUpdatedBy": "Test user",
  "validFrom": "2019-09-23T12:50:15.456Z",
  "validUntil": "2020-09-24T08:53:24.134Z",
  "isComprehensive": false,
  "codeBlocks": [
    {
      "codeBlockIndex": 1,
      "codeBlockType": "DOCUMENTATION",
      "codeBlockValue": "%md\n# Process beskrivelse\nHer beskriver du hva det er dette process steget skal gjøre\n\n## Input\n- Lag en liste over de inputer som skal ingå i dette steget\n\n## Output\n- Lad en liste over de resultater som forventes av steget"
    },
    {
      "codeBlockIndex": 2,
      "codeBlockType": "CODE",
      "codeBlockValue": "%pyspark # Oppgi hvilket språk du skriver i\n\n# Første paragraf skal inneholde de bibliotekene som skal benyttes i dette process steget\nfrom pyspark.sql import SparkSession \nfrom pyspark.sql.types import *\nimport pyspark.sql.functions as F\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql.functions import broadcast"
    },
    {
      "codeBlockIndex": 3,
      "codeBlockType": "CODE",
      "codeBlockValue": "%pyspark\n#==== Initiate Spark Session ====#\nspark = (SparkSession.builder.appName(\"Test_case\")\\\n                    .config(\"spark.executor.memory\", \"12g\")\\\n                    .config(\"spark.executor.cores\", 6)\\\n                    .config('spark.dynamicAllocation.maxExecutors', '6')\\\n                    .getOrCreate())\n                    \na = 0.25"
    },
    {
      "codeBlockIndex": 4,
      "codeBlockType": "CODE",
      "codeBlockValue": "%pyspark\n#Importer alle datasett du skal bruke i dette process steget\ndf = spark.read.load('gs://somedata/data/auto.parquet')\ndf2 = spark.read.load('gsim-link')"
    },
    {
      "codeBlockIndex": 5,
      "codeBlockType": "DOCUMENTATION",
      "codeBlockValue": "%md\n### Sub-steg titel\n\nEt process steg består av mange forskjellige underoppgaver.\nI dette avsnittet ønsker vi at du skriver inn en beskrivelse av det neste steget.\nDet skal være en tekst paragraph (%md) før hver kode blok som skrives."
    },
    {
      "codeBlockIndex": 6,
      "codeBlockType": "DOCUMENTATION",
      "codeBlockValue": "%pyspark # Skriv hvilket språk du bruker her\n# Skriv inn den ønskede koden her."
    },
    {
      "codeBlockIndex": 7,
      "codeBlockType": "DOCUMENTATION",
      "codeBlockValue": "%md\n### Sub-steg titel\n\nEt process steg består av mange forskjellige underoppgaver.\nI dette avsnittet ønsker vi at du skriver inn en beskrivelse av det neste steget.\nDet skal være en tekst paragraph (%md) før hver kode blok som skrives."
    },
    {
      "codeBlockIndex": 8,
      "codeBlockType": "DOCUMENTATION",
      "codeBlockValue": "%pyspark # Skriv hvilket språk du bruker her\n# Skriv inn den ønskede koden her."
    },
    {
      "codeBlockIndex": 9,
      "codeBlockType": "DOCUMENTATION",
      "codeBlockValue": "%md\n### Sub-steg titel\n\nEt process steg består av mange forskjellige underoppgaver.\nI dette avsnittet ønsker vi at du skriver inn en beskrivelse av det neste steget.\nDet skal være en tekst paragraph (%md) før hver kode blok som skrives."
    },
    {
      "codeBlockIndex": 10,
      "codeBlockType": "DOCUMENTATION",
      "codeBlockValue": "%pyspark # Skriv hvilket språk du bruker her\n# Skriv inn den ønskede koden her."
    },
    {
      "codeBlockIndex": 11,
      "codeBlockType": "DOCUMENTATION",
      "codeBlockValue": "%pyspark\n# Skriv ut utput"
    }
  ]
}